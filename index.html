<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>CoRI</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="./static/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <style>
        .features {
            list-style-type: disc;  /* solid round bullets */
            margin-left: 1.5em;     /* indent to taste */
        }

        .lead-video-player-wrapper {
            border-radius: 15px;
            overflow: hidden;
            background-color: #363636;
            position: relative;
            margin: 0 auto 1rem;
            display: block;
            width: 80%;
            aspect-ratio: 16 / 9;
        }
      
        .lead-video-player-wrapper video {
            display: block;
            width: 100%;  
            height: auto; 
        }
      
        .video-thumbnail-strip {
            display: flex;            
            flex-direction: column; 
            flex-wrap: nowrap;        
            gap: 10px;               
            justify-content: flex-start; 
            align-items: center;
        }
      
        .video-thumbnail-strip .thumbnail-video-wrapper {
            position: relative;
            width: 12vw;
            aspect-ratio: 16 / 9;
            border-radius: 8px;
            overflow: hidden;
            cursor: pointer;
            border: 3px solid transparent;
            transition: border-color 0.2s ease-in-out,
                        transform    0.2s ease-in-out;
            background-color: #2b2b2b;
        }
      
        .video-thumbnail-strip .thumbnail-video-wrapper video.thumbnail-video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            pointer-events: none;
            display: block;
        }
      
        .video-thumbnail-strip .thumbnail-video-wrapper:hover {
            border-color: #FFD4D4;
            transform: scale(1.05);
        }
      
        .video-thumbnail-strip .thumbnail-video-wrapper.active {
            border-color: #FF8282;
            transform: scale(1.05);
        }
      </style>
</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">


                        <h1 class="title is-1 publication-title">
                         CoRI: Synthesizing Communication of Robot Intent for Physical Human-Robot Interaction
                        </h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a target="_blank" href="https://cori-phri.github.io"> Anonymous Submission</a>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">CoRL 2025</span>
                        </div>

                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section" style="padding: 0">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <img src="images/main-fig.png" alt="main figure" style="width:100%; height:auto;">
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p style="font-size: 125%">
                            Clear communication of robot intent fosters transparency and interpretability in physical human-robot interaction (pHRI), particularly during assistive tasks involving direct human-robot contact. We introduce CoRI, a pipeline that automatically generates natural language communication of a robot's upcoming actions directly from its motion plan and visual perception. Our pipeline first processes the robot's image view to identify human poses and key environmental features. It then encodes the planned 3D spatial trajectory (including velocity and force) onto this view, visually grounding the path and its dynamics. CoRI queries a vision-language model with this visual representation to interpret the planned action within the visual context before generating concise, user-directed statements, without relying on task-specific information. Results from a user study involving robot-assisted feeding, bathing, and shaving tasks across two different robots indicate that CoRI leads to statistically significant difference in communication clarity compared to a baseline communication strategy. Specifically, CoRI effectively conveys not only the robot's high-level intentions but also crucial details about its motion any necessary user cooperation.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3">Overview Video</h2>
                        <div class="columns is-centered has-text-centered"> 
                            <video poster="" id="" controls width="100%" playbackRate=2.0 style="border-radius: 5px;">
                                <source src="videos/overview.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">CoRI Pipeline Details</span></h2>
                        <img src="images/system-fig.png" class="interpolation-image" alt=""
                        style="display: block; margin-left: auto; margin-right: auto; max-width: 90%;" />
                        <br>
                        <span style="font-size: 125%"><strong>Overview: </strong> Our CoRI pipeline takes as input an image observation of the environment and person, along with a planned 3D trajectory of any robot. CoRI first performs interaction-aware trajectory encoding to extract body landmarks, segment the trajectory, and visually encode the planned motion into visual context. Finally, it queries a VLM and a reasoning LLM respectively to interpret the visual information and generate user-oriented verbal communication. CoRI is designed to be <strong>task-agnostic</strong>, hence not requiring any task-specific information, and allows any robot to communicate to a non-expert user in the following three aspects: 
                            <ul class="features">
                            <li>The overall <strong>intention</strong> of the robot. This is the task-level goal that the robot aims to achieve.</li>
                            <li>All aspects of the <strong>motion</strong> of the robot. This includes details regarding the planned trajectory itself&mdash;starting and ending positions, shape of the trajectory, as well as velocity and force profiles. Furthermore, these descriptions are intuitive&mdash;without any numerical values, but with references to the robot's surroundings and with comparative language.</li>
                            <li>If needed, <strong>user cooperation</strong>. We recognize that many assistive tasks require certain behaviors from the user in order for the overall interaction to be successful (e.g. user taking a bite during feeding). Hence, our pipeline also conveys any desired human behavior.</li>
                            </ul> 
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Application in pHRI Tasks</span></h2>
                        <h3 class="title is-4"><span class="dvima">Bathing</span></h3>
                        <div class="columns is-vcentered">
                            <div class="column is-narrow">
                                <div class="video-thumbnail-strip" id="bathing-thumbs">
                                    <div class="thumbnail-video-wrapper" data-video-src="videos/bathing-1.mp4">
                                        <video class="thumbnail-video" src="videos/bathing-1.mp4" poster="images/bathing-1.jpg" muted preload="metadata" playsinline></video>
                                    </div>
                                    <div class="thumbnail-video-wrapper" data-video-src="videos/bathing-2.mp4">
                                        <video class="thumbnail-video" src="videos/bathing-2.mp4" poster="images/bathing-2.jpg" muted preload="metadata" playsinline></video>
                                    </div>
                                </div>
                            </div>
                            <div class="column">
                                <div class="lead-video-player-wrapper">
                                    <video id="bathing-lead-video" src="videos/bathing-1.mp4" controls preload="auto"></video>
                                </div>
                            </div>
                        </div>
                        <br>
                        <br>
                        <h3 class="title is-4"><span class="dvima">Shaving</span></h3>
                        <div class="columns is-vcentered">
                            <div class="column is-narrow">
                                <div class="video-thumbnail-strip" id="shaving-thumbs">
                                    <div class="thumbnail-video-wrapper" data-video-src="videos/shaving-2.mp4">
                                        <video class="thumbnail-video" src="videos/shaving-2.mp4" poster="images/shaving-1.jpg" muted preload="metadata" playsinline></video>
                                    </div>
                                    <div class="thumbnail-video-wrapper" data-video-src="videos/shaving-1.mp4">
                                        <video class="thumbnail-video" src="videos/shaving-1.mp4" poster="images/shaving-2.jpg" muted preload="metadata" playsinline></video>
                                    </div>
                                </div>
                            </div>
                            <div class="column">
                                <div class="lead-video-player-wrapper">
                                    <video id="shaving-lead-video" src="videos/shaving-2.mp4" controls preload="auto"></video>
                                </div>
                            </div>
                        </div>
                        <br>
                        <br>
                        <h3 class="title is-4"><span class="dvima">Feeding</span></h3>
                        <div class="columns is-vcentered">
                            <div class="column is-narrow">
                                <div class="video-thumbnail-strip" id="feeding-thumbs">
                                    <div class="thumbnail-video-wrapper" data-video-src="videos/feeding-1.mp4">
                                        <video class="thumbnail-video" src="videos/feeding-1.mp4" poster="images/feeding-1.jpg" muted preload="metadata" playsinline></video>
                                    </div>
                                    <div class="thumbnail-video-wrapper" data-video-src="videos/feeding-2.mp4">
                                        <video class="thumbnail-video" src="videos/feeding-2.mp4" poster="images/feeding-2.jpg" muted preload="metadata" playsinline></video>
                                    </div>
                                </div>
                            </div>
                            <div class="column">
                                <div class="lead-video-player-wrapper">
                                    <video id="feeding-lead-video" src="videos/feeding-1.mp4" controls preload="auto"></video>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

</body>

<script>

  timeoutIds = [];

    function typeWriter(txt, i, q, num, text1, text2) {
        var imgText = document.getElementById(text1 + num);
        var answer = document.getElementById(text2 + num);
        if (imgText.innerHTML == q) {
            for (let k = 0; k < 5; k++) {
                if (i < txt.length) {
                    if (txt.charAt(i) == "\\") {
                        answer.innerHTML += "\n";
                        i += 1;
                    } else {
                        answer.innerHTML += txt.charAt(i);
                    }
                    i++;
                }
            }
            hljs.highlightAll();
            timeoutIds.push(setTimeout(typeWriter, 1, txt, i, q, num, text1, text2));
        }
    }

    function setupVideoGallery(galleryId, leadVideoId) {
        const gallery = document.getElementById(galleryId);
        if (!gallery) { /* console.warn("Gallery not found:", galleryId); */ return; }
        const leadVideo = document.getElementById(leadVideoId);
        if (!leadVideo) { /* console.warn("Lead video not found:", leadVideoId); */ return; }
        
        const thumbnailWrappers = gallery.querySelectorAll('.thumbnail-video-wrapper'); 
        if (thumbnailWrappers.length === 0) { /* console.warn("No thumbnails in gallery:", galleryId); */ return; }

        if (thumbnailWrappers[0] && thumbnailWrappers[0].dataset.videoSrc) {
            leadVideo.src = thumbnailWrappers[0].dataset.videoSrc;
            thumbnailWrappers[0].classList.add('active');
        }

        thumbnailWrappers.forEach(wrapper => {
            wrapper.addEventListener('click', function() {
                leadVideo.src = this.dataset.videoSrc;
                thumbnailWrappers.forEach(thumbWrap => thumbWrap.classList.remove('active'));
                this.classList.add('active');
            });
        });
    }

    setupVideoGallery('bathing-thumbs', 'bathing-lead-video');
    setupVideoGallery('shaving-thumbs', 'shaving-lead-video');
    setupVideoGallery('feeding-thumbs', 'feeding-lead-video');

</script>

</html>